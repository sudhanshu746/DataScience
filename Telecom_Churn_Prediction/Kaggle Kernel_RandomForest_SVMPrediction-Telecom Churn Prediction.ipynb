{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# We are predicting percentage of subscribers to a service who discontinue their subscriptions to the service within a given time period\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.ticker as mtic\nimport matplotlib.pyplot as plot\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "telecomDf = pd.read_csv('../input/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ntelecomDf.head()\n# Lets examine variables for feature selection\ntelecomDf.columns.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d84401400977a453821304071d8cf5b422c6116"
      },
      "cell_type": "code",
      "source": "# Checking the data types of all the columns\ntelecomDf.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58d42f28bac9608e142bbbfeca6f24bb8e7d252f"
      },
      "cell_type": "code",
      "source": "# Now lets explore if is there any missing or null values \ntelecomDf.TotalCharges = pd.to_numeric(telecomDf.TotalCharges, errors='coerce')\ntelecomDf.isna().any() # All False confirm there is no missing values\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "772bdc37c4631b4fd441d5a5c3413320a758dcb1"
      },
      "cell_type": "code",
      "source": "# Preprocessing\ntelecomDf.isnull().sum()\n# There are 11 missing value for Total Charges, lets remove these 11 values having missing data from dataset\n# Remove NA values \ntelecomDf.dropna(inplace = True)\n# Lets remove customerId from dataset, which is not required for model\ntelecomDf4dummy = telecomDf.iloc[:,1:]\n# Converting Label variable i'e Churn to binary Numerical  \ntelecomDf4dummy['Churn'].replace(to_replace='No',value=0,inplace=True)\ntelecomDf4dummy['Churn'].replace(to_replace='Yes',value=1,inplace=True)\n\n# Convert categorical variable into dummy/indicator variables\n# pd.get_dummies creates a new dataframe which consists of zeros and ones.\ndummiesDf = pd.get_dummies(telecomDf4dummy)\ndummiesDf.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ecce39a620d8d5475e71b139bf9c81317eedfbc8"
      },
      "cell_type": "code",
      "source": "# Feature Selection \n\n# Now Lets check correlation of Churn with other variables\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,10))\ndummiesDf.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')\n'''\nNow, we have below predictor/independent variables\nContact Month-To-Month\nTenure\nTotal Charges\nOnline Security\nTech Support_No\nInternet_service_FiberOptics\n\nplt.figure(figsize=(20,10))\ndf_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')\nplt.figure(figsize=(15,10))\ndf_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')\n'''\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b1edc9cf472a7d0e3c2ce90284022089dcd3b76"
      },
      "cell_type": "code",
      "source": "#  Conclusion:  As per correlation, Month to month contracts, absence of online security and tech support seem to be positively correlated with churn.\n#  While, tenure, two year contracts and Internet Service seem to be negatively correlated with churn.\n# services such as Online security, streaming TV, online backup, tech support, Device protection, Partner and Streaming movies without internet connection seem to be negatively related to churn.\n\nY = dummiesDf['Churn'].values\n#Accuracy 79.95\nX = dummiesDf.drop(columns = ['Churn'])\n# Accuracy 78.31%\n#selected_features = ['Contract_Month-to-month','tenure','TotalCharges']\n#Accuracy 79.31%\nselected_features =['Contract_Month-to-month','tenure','TotalCharges','OnlineSecurity_No','TechSupport_No','InternetService_Fiber optic','PaymentMethod_Electronic check','MonthlyCharges','Contract_Two year','InternetService_DSL']\n#Accuracy 76.46%\n#selected_features=['Contract_Month-to-month','OnlineSecurity_No','TechSupport_No','tenure','Contract_Two year']\n#Accuracy 79.53%\n#selected_features=X.drop(columns=['PhoneService_Yes','gender_Female','gender_Male','PhoneService_No']).columns.values\nX_select = X[selected_features]\n# Lets scale all the variables from a range of 0 to 1\n# Transforms features by scaling each feature to a given range.\n#This estimator scales and translates each feature individually such that it is in the given range on the training set (0,1).\nfrom sklearn.preprocessing import MinMaxScaler\nfeatures = X.columns.values\nscaler = MinMaxScaler(feature_range=(0,1))\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X))\nX.columns = features\n\n# Selected features\nscaler.fit(X_select)\nX_select = pd.DataFrame(scaler.transform(X_select))\nX_select.columns=selected_features\n\nX_select.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "332aeab2b98ed1f352b74174242f954cae6d4e5f"
      },
      "cell_type": "code",
      "source": "'''\n1. Let's use Random forest classifier to approach Telecom churn data\nWhy Random forest ?\nRandom forest classifier is trademark term for an ensemble of decision tree\nensemble models combines several decision trees to produce better predictive performance than utilizing a single decision tree.\ntrain_test_split: Split arrays/matrices into random train and test subsets, we are taking 20% data  as test. Random_states is seed value used by the random number generator\n'''\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=99)\nrandomForestModel = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,random_state =50, max_features = \"auto\",max_leaf_nodes = 30)\nrandomForestModel.fit(x_train,y_train)\ntestPrediction =  randomForestModel.predict(x_test)\nprint(metrics.accuracy_score(y_test,testPrediction))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ea181ed148c2f0471f3c8a466d6c39c1722aac5"
      },
      "cell_type": "code",
      "source": "importances = randomForestModel.feature_importances_\nweights = pd.Series(importances,index=X.columns.values)\nweights.sort_values()[-10:].plot(kind = 'barh')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "008d9d43cd3a39701bfc71b1e06fa9eac3b8d7de"
      },
      "cell_type": "code",
      "source": "'''\n2.1 Let's use Random forest classifier to approach Telecom churn data on selected features\n'''\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nx_train, x_test, y_train, y_test = train_test_split(X_select, Y, test_size=0.2, random_state=99)\nrandomForestModel = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,random_state =50, max_features = \"auto\",max_leaf_nodes = 30)\nrandomForestModel.fit(x_train,y_train)\ntestPrediction =  randomForestModel.predict(x_test)\nprint(metrics.accuracy_score(y_test,testPrediction))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2293d09caa31c05ad124fce2e75ef1ae280013e2"
      },
      "cell_type": "code",
      "source": "# Confusion Matrix Validation \nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test,testPrediction))  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ae3e3d197b3a6773dfad1cf53b58a2600f32620e"
      },
      "cell_type": "code",
      "source": "# 3. Lets check performance with SVM ( Support Vecor Machine) Model\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=99)\nfrom sklearn.svm import SVC\n\nmodelSVM = SVC(kernel='linear') \nmodelSVM.fit(X_train,y_train)\npreds = modelSVM.predict(X_test)\nmetrics.accuracy_score(y_test, preds)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7146da96070c79e1c93a92ecf186c8be1b7344a3"
      },
      "cell_type": "code",
      "source": "# Create the Confusion matrix for SVM\nfrom sklearn.metrics import classification_report, confusion_matrix  \nprint(confusion_matrix(y_test,preds))  ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}